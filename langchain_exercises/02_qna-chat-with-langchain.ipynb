{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Chat on private data using LangChain\n",
    "\n",
    "Firstly, create a file called `.env` in this folder, and add the following content, obviously with your values:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxxxx\n",
    "OPENAI_API_BASE=https://xxxxxxx.openai.azure.com/\n",
    "```\n",
    "\n",
    "Then, let's install all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did load from env file?: True\n",
      "got embeddings with shape (1, 1536)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables (set OPENAI_API_KEY and OPENAI_API_BASE in .env)\n",
    "print(\"Did load from env file?:\", load_dotenv('../.env'))\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# Init LLM and embeddings model\n",
    "llm = AzureChatOpenAI(deployment_name=\"gpt-35-turbo\", temperature=0, openai_api_version=\"2023-03-15-preview\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\", \n",
    "    openai_api_base=os.getenv('OPENAI_API_BASE'),\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    openai_api_version=\"2023-03-15-preview\",\n",
    "    openai_api_type=\"azure\",\n",
    "    chunk_size=1)\n",
    "\n",
    "embed_vals = embeddings.embed_documents([\"Hello, how are you?\"])\n",
    "print(f\"got embeddings with shape {np.array(embed_vals).shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load up our documents from the `data` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 6 in 0.01 seconds\n",
      "[Document(page_content='\\n# What is Azure OpenAI?\\n\\nThe Azure OpenAI service provides REST API access to OpenAI\\'s powerful language models including the GPT-3, Codex and Embeddings model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\\n\\n### Features overview\\n\\n| Feature | Azure OpenAI |\\n| --- | --- |\\n| Models available | GPT-3 base series <br> Codex series <br> Embeddings series <br> Learn more in our [Models](./concepts/models.md) page.|\\n| Fine-tuning | Ada <br> Babbage <br> Curie <br> Cushman* <br> Davinci* <br> \\\\* available by request. Please open a support request|\\n| Price | [Available here](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) |\\n| Virtual network support | Yes | \\n| Managed Identity| Yes, via Azure Active Directory | \\n| UI experience | **Azure Portal** for account & resource management, <br> **Azure OpenAI Service Studio** for model exploration and fine tuning |\\n| Regional availability | East US <br> South Central US <br> West Europe |\\n| Content filtering | Prompts and completions are evaluated against our content policy with automated systems. High severity content will be filtered. |\\n\\n## Responsible AI\\n\\nAt Microsoft, we\\'re committed to the advancement of AI driven by principles that put people first. Generative models such as the ones available in the Azure OpenAI service have significant potential benefits, but without careful design and thoughtful mitigations, such models have the potential to generate incorrect or even harmful content. Microsoft has made significant investments to help guard against abuse and unintended harm, which includes requiring applicants to show well-defined use cases, incorporating Microsoft’s <a href=\"https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\" target=\"_blank\">principles for responsible AI use</a>, building content filters to support customers, and providing responsible AI implementation guidance to onboarded customers.\\n\\n## How do I get access to Azure OpenAI?\\n\\nHow do I get access to Azure OpenAI Service?\\n\\nAccess is currently limited as we navigate high demand, upcoming product improvements, and <a href=\"https://www.microsoft.com/ai/responsible-ai?activetab=pivot1:primaryr6\" target=\"_blank\">Microsoft’s commitment to responsible AI</a>. For now, we\\'re working with customers with an existing partnership with Microsoft, lower risk use cases, and those committed to incorporating mitigations. In addition to applying for initial access, all solutions using the Azure OpenAI service are required to go through a use case review before they can be released for production use.\\n\\nMore specific information is included in the application form. We appreciate your patience as we work to responsibly enable broader access to the Azure OpenAI service.\\n\\nApply here for initial access or for a production review:\\n\\n<a href=\"https://aka.ms/oaiapply\" target=\"_blank\">Apply now</a>\\n\\nAll solutions using the Azure OpenAI service are also required to go through a use case review before they can be released for production use, and are evaluated on a case-by-case basis. In general, the more sensitive the scenario the more important risk mitigation measures will be for approval.\\n\\n## Comparing Azure OpenAI and OpenAI\\n\\nAzure OpenAI Service gives customers advanced language AI with OpenAI GPT-3, Codex, and DALL-E models with the security and enterprise promise of Azure. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.\\n\\nWith Azure OpenAI, customers get the security capabilities of Microsoft Azure while running the same models as OpenAI. Azure OpenAI offers private networking, regional availability, and responsible AI content filtering.  \\n\\n## Key concepts\\n\\n### Prompts & Completions\\n\\nThe completions endpoint is the core component of the API service. This API provides access to the model\\'s text-in, text-out interface. Users simply need to provide an input  **prompt** containing the English text command, and the model will generate a text **completion**.\\n\\nHere\\'s an example of a simple prompt and completion:\\n\\n>**Prompt', metadata={'source': '../data/qna/overview_openai.txt'}), Document(page_content='**:\\n        ```\\n        \"\"\"\\n        count to 5 in a for loop\\n        \"\"\"\\n        ```\\n>\\n>**Completion**:\\n        ```\\n        for i in range(1, 6):\\n            print(i)\\n        ```\\n\\n### Tokens\\n\\nOpenAI Enterprise processes text by breaking it down into tokens. Tokens can be words or just chunks of characters. For example, the word “hamburger” gets broken up into the tokens “ham”, “bur” and “ger”, while a short and common word like “pear” is a single token. Many tokens start with a whitespace, for example “ hello” and “ bye”.\\n\\nThe total number of tokens processed in a given request depends on the length of your input, output and request parameters. The quantity of tokens being processed will also affect your response latency and throughput for the models.\\n\\n### Resources\\n\\nThe Azure OpenAI service is a new product offering on Azure. You can get started with the Azure OpenAI service the same way as any other Azure product where you [create a resource](how-to/create-resource.md), or instance of the service, in your Azure Subscription. You can read more about Azure\\'s [resource management design](../../azure-resource-manager/management/overview.md).\\n\\n### Deployments\\n\\nOnce you create an Azure OpenAI Resource, you must deploy a model before you can start making API calls and generating text. This action can be done using the Deployment APIs. These APIs allow you to specify the model you wish to use.\\n\\n### In-context learning\\n\\nThe models used by the Azure OpenAI service use natural language instructions and examples provided during the generation call to identify the task being asked and skill required. When you use this approach, the first part of the prompt includes natural language instructions and/or examples of the specific task desired. The model then completes the task by predicting the most probable next piece of text. This technique is known as \"in-context\" learning. These models aren\\'t retrained during this step but instead give predictions based on the context you include in the prompt.\\n\\nThere are three main approaches for in-context learning: Few-shot, one-shot and zero-shot. These approaches vary based on the amount of task-specific data that is given to the model:\\n\\n**Few-shot**: In this case, a user includes several examples in the call prompt that demonstrate the expected answer format and content. The following example shows a few-shot prompt where we provide multiple examples (the model will generate the last answer):\\n\\n```\\n    Convert the questions to a command:\\n    Q: Ask Constance if we need some bread.\\n    A: send-msg `find constance` Do we need some bread?\\n    Q: Send a message to Greg to figure out if things are ready for Wednesday.\\n    A: send-msg `find greg` Is everything ready for Wednesday?\\n    Q: Ask Ilya if we\\'re still having our meeting this evening.\\n    A: send-msg `find ilya` Are we still having a meeting this evening?\\n    Q: Contact the ski store and figure out if I can get my skis fixed before I leave on Thursday.\\n    A: send-msg `find ski store` Would it be possible to get my skis fixed before I leave on Thursday?\\n    Q: Thank Nicolas for lunch.\\n    A: send-msg `find nicolas` Thank you for lunch!\\n    Q: Tell Constance that I won\\'t be home before 19:30 tonight — unmovable meeting.\\n    A: send-msg `find constance` I won\\'t be home before 19:30 tonight. I have a meeting I can\\'t move.\\n    Q: Tell John that I need to book an appointment at 10:30.\\n    A: \\n```\\n\\nThe number of examples typically range from 0 to 100 depending on how many can fit in the maximum input length for a single prompt. Maximum input length can vary depending on the specific models you use. Few-shot learning enables a major reduction in the amount of task-specific data required for accurate predictions. This', metadata={'source': '../data/qna/overview_openai.txt'}), Document(page_content=' approach will typically perform less accurately than a fine-tuned model.\\n\\n**One-shot**: This case is the same as the few-shot approach except only one example is provided. \\n\\n**Zero-shot**: In this case, no examples are provided to the model and only the task request is provided.\\n\\n### Models\\n\\nThe service provides users access to several different models. Each model provides a different capability and price point. The GPT-3 base models are known as Davinci, Curie, Babbage, and Ada in decreasing order of capability and increasing order of speed.\\n\\nThe Codex series of models is a descendant of GPT-3 and has been trained on both natural language and code to power natural language to code use cases. Learn more about each model on our [models concept page](./concepts/models.md).\\n\\n## Next steps\\n\\nLearn more about the [underlying models that power Azure OpenAI](./concepts/models.md).\\n', metadata={'source': '../data/qna/overview_openai.txt'}), Document(page_content='\\n# What is Azure Cognitive Services Translator?\\n\\nTranslator Service is a cloud-based neural machine translation service that is part of the [Azure Cognitive Services](../what-are-cognitive-services.md) family of REST APIs and can be used with any operating system. Translator powers many Microsoft products and services used by thousands of businesses worldwide to perform language translation and other language-related operations. In this overview, you\\'ll learn how Translator can enable you to build intelligent, multi-language solutions for your applications across all [supported languages](./language-support.md).\\n\\nTranslator documentation contains the following article types:\\n\\n* [**Quickstarts**](quickstart-translator.md). Getting-started instructions to guide you through making requests to the service.\\n* [**How-to guides**](translator-text-apis.md). Instructions for accessing and using the service in more specific or customized ways.\\n* [**Reference articles**](reference/v3-0-reference.md). REST API documentation and programming language-based content.\\n\\n## Translator features and development options\\n\\nThe following features are supported by the Translator service. Use the links in this table to learn more about each feature and browse the API references.\\n\\n| Feature | Description | Development options |\\n|----------|-------------|--------------------------|\\n| [**Text Translation**](text-translation-overview.md) | Execute text translation between supported source and target languages in real time. | <ul><li>[**REST API**](reference/rest-api-guide.md) </li><li>[Text translation Docker container](containers/translator-how-to-install-container.md).</li></ul> |\\n| [**Document Translation**](document-translation/overview.md) | Translate batch and complex files while preserving the structure and format of the original documents. | <ul><li>[**REST API**](document-translation/reference/rest-api-guide.md)</li><li>[**Client-library SDK**](document-translation/how-to-guides/use-client-sdks.md)</li></ul> |\\n| [**Custom Translator**](custom-translator/overview.md) | Build customized models to translate domain- and industry-specific language, terminology, and style. | <ul><li>[**Custom Translator portal**](https://portal.customtranslator.azure.ai/)</li></ul> |\\n\\n## Try the Translator service for free\\n\\nFirst, you\\'ll need a Microsoft account; if you don\\'t have one, you can sign up for free at the [**Microsoft account portal**](https://account.microsoft.com/account).  Select **Create a Microsoft account** and follow the steps to create and verify your new account.\\n\\nNext, you\\'ll need to  have an Azure account—navigate to the [**Azure sign-up page**](https://azure.microsoft.com/free/ai/), select the **Start free** button, and create a new Azure account using your Microsoft account credentials.\\n\\nNow, you\\'re ready to get started! [**Create a Translator service**](how-to-create-translator-resource.md \"Go to the Azure portal.\"), [**get your access keys and API endpoint**](how-to-create-translator-resource.md#authentication-keys-and-endpoint-url \"An endpoint URL and read-only key are required for authentication.\"), and try our [**quickstart**](quickstart-translator.md \"Learn to use Translator via REST.\").\\n\\n## Next steps\\n\\n* Learn more about the following features:\\n  * [**Text Translation**](text-translation-overview.md)\\n  * [**Document Translation**](document-translation/overview.md)\\n  * [**Custom Translator**](custom-translator/overview.md)\\n* Review [**Translator pricing**](https://azure.microsoft.com/pricing/details/cognitive-services/translator-text-api/).\\n', metadata={'source': '../data/qna/overview_translator.txt'}), Document(page_content='\\n# What is conversational language understanding?\\n\\nConversational language understanding is one of the custom features offered by [Azure Cognitive Service for Language](../overview.md). It is a cloud-based API service that applies machine-learning intelligence to enable you to build natural language understanding component to be used in an end-to-end conversational application. \\n\\nConversational language understanding (CLU) enables users to build custom natural language understanding models to predict the overall intention of an incoming utterance and extract important information from it. CLU only provides the intelligence to understand the input text for the client application and doesn\\'t perform any actions. By creating a CLU project, developers can iteratively label utterances, train and evaluate model performance before making it available for consumption. The quality of the labeled data greatly impacts model performance. To simplify building and customizing your model, the service offers a custom web portal that can be accessed through the [Language studio](https://aka.ms/languageStudio). You can easily get started with the service by following the steps in this [quickstart](quickstart.md). \\n\\nThis documentation contains the following article types:\\n\\n* [Quickstarts](quickstart.md) are getting-started instructions to guide you through making requests to the service.\\n* [Concepts](concepts/evaluation-metrics.md) provide explanations of the service functionality and features.\\n* [How-to guides](how-to/create-project.md) contain instructions for using the service in more specific or customized ways.\\n\\n\\n## Example usage scenarios\\n\\nCLU can be used in multiple scenarios across a variety of industries. Some examples are:\\n\\n### End-to-end conversational bot\\n\\nUse CLU to build and train a custom natural language understanding model based on a specific domain and the expected users\\' utterances. Integrate it with any end-to-end conversational bot so that it can process and analyze incoming text in real time to identify the intention of the text and extract important information from it. Have the bot perform the desired action based on the intention and extracted information. An example would be a customized retail bot for online shopping or food ordering.\\n\\n### Human assistant bots\\n\\nOne example of a human assistant bot is to help staff improve customer engagements by triaging customer queries and assigning them to the appropriate support engineer. Another example would be a human resources bot in an enterprise that allows employees to communicate in natural language and receive guidance based on the query.\\n\\n### Command and control application\\n\\nWhen you integrate a client application with a speech-to-text component, users can speak a command in natural language for CLU to process, identify intent, and extract information from the text for the client application to perform an action. This use case has many applications, such as to stop, play, forward, and rewind a song or turn lights on or off.\\n\\n### Enterprise chat bot\\n\\nIn a large corporation, an enterprise chat bot may handle a variety of employee affairs. It might handle frequently asked questions served by a custom question answering knowledge base, a calendar specific skill served by conversational language understanding, and an interview feedback skill served by LUIS. Use Orchestration workflow to connect all these skills together and appropriately route the incoming requests to the correct service.\\n\\n\\n## Project development lifecycle\\n\\nCreating a CLU project typically involves several different steps. \\n\\n:::image type=\"content\" source=\"media/development-lifecycle.png\" alt-text=\"The development lifecycle\" lightbox=\"media/development-lifecycle.png\":::\\n\\nFollow these steps to get the most out of your model:\\n\\n1. **Define your schema**: Know your data and define the actions and relevant information that needs to be recognized from user\\'s input utterances. In this step you create the [intents](glossary.md#intent) that you want to assign to user\\'s utterances, and the relevant [entities](glossary.md#entity) you want extracted.\\n\\n2. **Label your data**: The quality of data labeling is a key factor in determining model performance. \\n\\n3. **Train the model**: Your model starts learning from your labeled data.\\n\\n4. **View the model\\'s performance**: View the evaluation details for your model to determine how well it performs when introduced to new data.\\n\\n6. **Improve the model**: After reviewing the model\\'s performance, you can then learn how you can improve the model.\\n\\n7. **Deploy the model**: Deploying a model makes it available for use via the [Runtime API](https://aka.ms/clu-apis).\\n\\n8. **Predict intents and entities', metadata={'source': '../data/qna/overview_clu.txt'}), Document(page_content=\"**: Use your custom model to predict intents and entities from user's utterances.\\n\\n## Reference documentation and code samples\\n\\nAs you use CLU, see the following reference documentation and samples for Azure Cognitive Services for Language:\\n\\n|Development option / language  |Reference documentation |Samples  |\\n|---------|---------|---------|\\n|REST APIs (Authoring)   | [REST API documentation](https://aka.ms/clu-authoring-apis)        |         |\\n|REST APIs (Runtime)    | [REST API documentation](https://aka.ms/clu-apis)        |         |\\n|C# (Runtime)    | [C# documentation](/dotnet/api/overview/azure/ai.language.conversations-readme)        | [C# samples](https://github.com/Azure/azure-sdk-for-net/tree/main/sdk/cognitivelanguage/Azure.AI.Language.Conversations/samples)        |\\n|Python (Runtime)| [Python documentation](/python/api/overview/azure/ai-language-conversations-readme?view=azure-python-preview&preserve-view=true)        | [Python samples](https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/cognitivelanguage/azure-ai-language-conversations/samples) |\\n\\n## Responsible AI \\n\\nAn AI system includes not only the technology, but also the people who will use it, the people who will be affected by it, and the environment in which it's deployed. Read the transparency note for CLU to learn about responsible AI use and deployment in your systems. You can also see the following articles for more information:\\n\\n[!INCLUDE [Responsible AI links](../includes/overview-responsible-ai-links.md)]\\n\\n## Next steps\\n\\n* Use the [quickstart article](quickstart.md) to start using conversational language understanding.  \\n\\n* As you go through the project development lifecycle, review the [glossary](glossary.md) to learn more about the terms used throughout the documentation for this feature. \\n\\n* Remember to view the [service limits](service-limits.md) for information such as [regional availability](service-limits.md#regional-availability).\\n\\n\", metadata={'source': '../data/qna/overview_clu.txt'})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from timeit import default_timer\n",
    "\n",
    "start_time = default_timer()\n",
    "loader = DirectoryLoader('../data/qna/', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "runtime = default_timer() - start_time\n",
    "print(f\"Number of documents: {len(docs)} in {runtime:.2f} seconds\")\n",
    "print(docs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's ingest them into FAISS so we can efficiently query our embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "db = FAISS.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a chain that can do the whole chat on our embedding database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Adapt if needed\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(\"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\")\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                           retriever=db.as_retriever(),\n",
    "                                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI is a service that provides REST API access to OpenAI's language models, including GPT-3, Codex, and Embeddings model series. These models can be used for content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or a web-based interface in the Azure OpenAI Studio. The service is available in East US, South Central US, and West Europe regions. Additionally, Azure OpenAI offers private networking, regional availability, and responsible AI content filtering.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"what is azure openai service?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to easy implement chat conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is Azure OpenAI Service?\n",
      "Answer: Azure OpenAI Service is a cloud-based service that provides REST API access to OpenAI's language models, including GPT-3, Codex, and Embeddings model series. These models can be used for various tasks such as content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or a web-based interface in the Azure OpenAI Studio. The service is built on Microsoft Azure and offers features such as virtual network support, managed identity, and responsible AI content filtering. However, access to the service is currently limited due to high demand and Microsoft's commitment to responsible AI.\n",
      "Question: Which regions does the service support?\n",
      "Answer: The Azure OpenAI Service is currently available in the East US, South Central US, and West Europe regions.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "query = \"what is Azure OpenAI Service?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n",
    "\n",
    "chat_history = [(query, result[\"answer\"])]\n",
    "query = \"Which regions does the service support?\"\n",
    "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is Azure OpenAI Service?\n",
      "Answer: Azure OpenAI Service is a cloud-based service provided by Microsoft Azure that allows developers to access OpenAI's powerful artificial intelligence models and tools. It enables developers to build intelligent applications that can understand natural language, recognize images, and perform other complex tasks.\n"
     ]
    }
   ],
   "source": [
    "#Now lets test if this is working without documents?\n",
    "chat_history = []\n",
    "\n",
    "#TODO: Fix this - define a list of text out of context.\n",
    "texts =\n",
    "db_no_docs = FAISS.from_texts(texts, embedding=embeddings)\n",
    "\n",
    "qa_no_retriever = ConversationalRetrievalChain.from_llm(llm=llm,\n",
    "                                           retriever=db_no_docs.as_retriever(),\n",
    "                                           condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)\n",
    "query = \"what is Azure OpenAI Service?\"\n",
    "result = qa_no_retriever({\"question\": query, \"chat_history\": chat_history})\n",
    "print(\"Question:\", query)\n",
    "print(\"Answer:\", result[\"answer\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
